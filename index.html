<!DOCTYPE html>
<html lang="en" xmlns="http://www.w3.org/1999/html">

<head>
  <meta charset="utf-8">
  <meta content="width=device-width, initial-scale=1.0" name="viewport">
  <title>XLLM Workshop @ ACL 2025</title>
  <meta name="description" content="">
  <meta name="keywords" content="">

  <!-- Favicons -->
  <link href="assets/img/favicon.png" rel="icon">
  <link href="assets/img/apple-touch-icon.png" rel="apple-touch-icon">

  <!-- Fonts -->
  <link href="https://fonts.googleapis.com" rel="preconnect">
  <link href="https://fonts.gstatic.com" rel="preconnect" crossorigin>
  <link href="https://fonts.googleapis.com/css2?family=Open+Sans:ital,wght@0,300;0,400;0,500;0,600;0,700;0,800;1,300;1,400;1,500;1,600;1,700;1,800&family=Montserrat:ital,wght@0,100;0,200;0,300;0,400;0,500;0,600;0,700;0,800;0,900;1,100;1,200;1,300;1,400;1,500;1,600;1,700;1,800;1,900&family=Poppins:ital,wght@0,100;0,200;0,300;0,400;0,500;0,600;0,700;0,800;0,900;1,100;1,200;1,300;1,400;1,500;1,600;1,700;1,800;1,900&display=swap" rel="stylesheet">

  <!-- Vendor CSS Files -->
  <link href="assets/vendor/bootstrap/css/bootstrap.min.css" rel="stylesheet">
  <link href="assets/vendor/bootstrap-icons/bootstrap-icons.css" rel="stylesheet">
  <link href="assets/vendor/aos/aos.css" rel="stylesheet">
  <link href="assets/vendor/glightbox/css/glightbox.min.css" rel="stylesheet">
  <link href="assets/vendor/swiper/swiper-bundle.min.css" rel="stylesheet">

  <!-- Main CSS File -->
  <link href="assets/css/main.css" rel="stylesheet">

  <!-- =======================================================
  * Template Name: Append
  * Template URL: https://bootstrapmade.com/append-bootstrap-website-template/
  * Updated: Aug 07 2024 with Bootstrap v5.3.3
  * Author: BootstrapMade.com
  * License: https://bootstrapmade.com/license/
  ======================================================== -->
</head>

<body class="index-page">

  <header id="header" class="header d-flex align-items-center fixed-top">
    <div class="container-fluid position-relative d-flex align-items-center justify-content-between" style="height: 20px">

      <a href="./" class="logo d-flex align-items-center me-auto me-xl-0">
<!--           style="margin-left: 200px"-->
        <!-- Uncomment the line below if you also wish to use an image logo -->
        <!-- <img src="assets/img/logo.png" alt=""> -->
<!--        <h1 class="sitename">XLLM 2025</h1>-->
      </a>

      <nav id="navmenu" class="navmenu">
<!--           style="margin-left: -200px"-->
        <ul>
          <li><a href="./" class="active">Overview</a></li>
          <li><a href="./#date">Important Dates</a></li>
          <li><a href="./#call">Call for Papers</a></li>
          <li><a href="./#keynote">Keynote Speakers</a></li>
          <li><a href="./#schedule">Schedule</a></li>
          <li><a href="./#task">Shared Tasks</a></li>
          <li><a href="./#organizer">Organizers</a></li>
          <li><a href="./#committee">Program Committee</a></li>
          <li><a href="./#contact">Contact</a></li>
<!--          <li class="dropdown"><a href="#"><span>Previous Versions</span> <i class="bi bi-chevron-down toggle-dropdown"></i></a>-->
<!--            <ul>-->
<!--              <li><a href="#">Dropdown 1</a></li>-->
<!--              <li><a href="#">Dropdown 2</a></li>-->
<!--              <li><a href="#">Dropdown 3</a></li>-->
<!--              <li><a href="#">Dropdown 4</a></li>-->
<!--            </ul>-->
<!--          </li>-->
        </ul>
        <i class="mobile-nav-toggle d-xl-none bi bi-list"></i>
      </nav>

      <div></div>

<!--      <a class="btn-getstarted" href="./#about">Get Started</a>-->

    </div>
  </header>

  <main class="main">

    <!-- Hero Section -->
    <section id="hero" class="hero section dark-background">

      <img src="assets/img/Vienna-crop2.jpeg" alt="" data-aos="fade-in">

      <div class="container">
        <div class="row">
          <div class="col-lg-10" style="margin-left: 50px;margin-bottom: -50px;">
            <h1 data-aos="fade-up" data-aos-delay="100">XLLM @ <a href="https://2025.aclweb.org/">ACL 2025</a></h1>
            <br>
            <h3 data-aos="fade-up" data-aos-delay="100">The 1<sup>st</sup> Joint Workshop on Large Language Models and Structure Modeling</h3>
            <br>
            <p data-aos="fade-up" data-aos-delay="200">Vienna, Austria</p>
            <p data-aos="fade-up" data-aos-delay="200">July 27‚ÄìAugust 1st, 2025</p>
          </div>
        </div>
      </div>

    </section><!-- /Hero Section -->





    <!-- About Section -->
    <section id="about" class="about section light-background">

      <div class="container" data-aos="fade-up" data-aos-delay="100" style="    margin-top: -30px;">
        <div class="row align-items-xl-center gy-2">

          <div class="content">
            <h3 style=" margin-bottom: 30px;">Workshop Introduction</h3>
<!--            <h2>Ducimus rerum libero reprehenderit cumque</h2>-->
            <p align="justify">Language structure modeling has long been a crucial subfield of natural language processing (NLP) that entails understanding the underlying semantic or syntactic structure of language and texts. Language structures can broadly range from low-level morphological/syntactic types (e.g., dependency structures and phrasal constituent structures) to high-level discourse/semantic structures (e.g., semantic parsing, semantic role labeling, abstract meaning representation), and can even extend to more NLP applications, multi-lingual and multi-modal scenarios in a broader sense, such as information extraction and structured sentiment analysis, etc. In previous days, modeling, inferring, and learning about linguistic structures constituted an indispensable component in many NLP systems and were the key focus of a large proportion of NLP research.</p>

            <p align="justify">The methodologies and paradigms concerning language structure modeling have always changed dramatically since each deep learning revolution started around a decade ago. In the last two to three years, Large Language Models (LLMs) have emerged, demonstrating unprecedented language understanding and generalization capabilities in effectively addressing a wide range of tasks. This raises a critical question:
              <em style="color: orangered">Is NLP structure modeling still worth exploring in the LLM era? Do the methods and tasks before LLMs still hold value?</em></p>

            <p align="justify">On the one hand, we wonder whether previous NLP structure modeling tasks, such as those concerning morphological/syntactic/semantic/discourse structures and high-level structure-aware applications, can achieve <b>even stronger task performance</b> with the powerful capabilities of LLMs.</p>

            <p align="justify">On the other hand, we are also considering whether it is still necessary to model the underlying structures of language, given that large-scale pretraining on the surface form alone can endow LLMs with extraordinarily powerful language capabilities. <b>In particular, can language structure modeling be beneficial for improving or understanding LLMs?</b></p>

            <p align="justify">Thus, this 1st Joint Workshop on Large Language Models and Structure Modeling (XLLM 2025) at ACL 2025 aims to encourage discussions and highlight methods for language structure modeling in the era of LLMs. Specifically, we will explore two main directions:
              <b>LLM for Structure Modeling</b> (LLM4X) and <b>Structure Modeling for LLM</b> (X4LLM).</p>

<!--            <a href="#" class="read-more"><span>Read More</span><i class="bi bi-arrow-right"></i></a>-->
          </div>


          <h2 class="title is-3" style="margin-top: 40px;">üîîNews</h2>

          <div class="content has-text-justified">
            <p>
<!--              <b>üî• You can now visit the video record of the tutorial at <a href="https://www.youtube.com/watch?v=pHBT3zXxQX8">Youtube</a>!</b><br>-->
              <b>üî• [2024-12-25]: First call for paper is out! Welcome submissions!</b><br>
<!--              <b>üî• Our tutorial is about to start, at <u>room Summit 446</u> for in-person attendance!</b><br>-->
<!--              <b>üî• Also you may want to join our online Tutorial via this <a href="#"><s>Zoom link</s></a>!</b>-->
            </p>
            <br>
         </div>
<!--          <div class="col-xl-7">-->
<!--            <div class="row gy-4 icon-boxes">-->

<!--              <div class="col-md-6" data-aos="fade-up" data-aos-delay="200">-->
<!--                <div class="icon-box">-->
<!--                  <i class="bi bi-buildings"></i>-->
<!--                  <h3>Eius provident</h3>-->
<!--                  <p>Magni repellendus vel ullam hic officia accusantium ipsa dolor omnis dolor voluptatem</p>-->
<!--                </div>-->
<!--              </div> &lt;!&ndash; End Icon Box &ndash;&gt;-->

<!--              <div class="col-md-6" data-aos="fade-up" data-aos-delay="300">-->
<!--                <div class="icon-box">-->
<!--                  <i class="bi bi-clipboard-pulse"></i>-->
<!--                  <h3>Rerum aperiam</h3>-->
<!--                  <p>Autem saepe animi et aut aspernatur culpa facere. Rerum saepe rerum voluptates quia</p>-->
<!--                </div>-->
<!--              </div> &lt;!&ndash; End Icon Box &ndash;&gt;-->

<!--              <div class="col-md-6" data-aos="fade-up" data-aos-delay="400">-->
<!--                <div class="icon-box">-->
<!--                  <i class="bi bi-command"></i>-->
<!--                  <h3>Veniam omnis</h3>-->
<!--                  <p>Omnis perferendis molestias culpa sed. Recusandae quas possimus. Quod consequatur corrupti</p>-->
<!--                </div>-->
<!--              </div> &lt;!&ndash; End Icon Box &ndash;&gt;-->

<!--              <div class="col-md-6" data-aos="fade-up" data-aos-delay="500">-->
<!--                <div class="icon-box">-->
<!--                  <i class="bi bi-graph-up-arrow"></i>-->
<!--                  <h3>Delares sapiente</h3>-->
<!--                  <p>Sint et dolor voluptas minus possimus nostrum. Reiciendis commodi eligendi omnis quideme lorenda</p>-->
<!--                </div>-->
<!--              </div> &lt;!&ndash; End Icon Box &ndash;&gt;-->

<!--            </div>-->
<!--          </div>-->

        </div>
      </div>

    </section><!-- /About Section -->

    <!-- Stats Section -->
<!--    <section id="stats" class="stats section dark-background">-->

<!--      <img src="assets/img/stats-bg.jpg" alt="" data-aos="fade-in">-->

<!--      <div class="container position-relative" data-aos="fade-up" data-aos-delay="100">-->

<!--        <div class="row gy-4">-->

<!--          <div class="col-lg-3 col-md-6">-->
<!--            <div class="stats-item text-center w-100 h-100">-->
<!--              <span data-purecounter-start="0" data-purecounter-end="232" data-purecounter-duration="1" class="purecounter"></span>-->
<!--              <p>Clients</p>-->
<!--            </div>-->
<!--          </div>&lt;!&ndash; End Stats Item &ndash;&gt;-->

<!--          <div class="col-lg-3 col-md-6">-->
<!--            <div class="stats-item text-center w-100 h-100">-->
<!--              <span data-purecounter-start="0" data-purecounter-end="521" data-purecounter-duration="1" class="purecounter"></span>-->
<!--              <p>Projects</p>-->
<!--            </div>-->
<!--          </div>&lt;!&ndash; End Stats Item &ndash;&gt;-->

<!--          <div class="col-lg-3 col-md-6">-->
<!--            <div class="stats-item text-center w-100 h-100">-->
<!--              <span data-purecounter-start="0" data-purecounter-end="1453" data-purecounter-duration="1" class="purecounter"></span>-->
<!--              <p>Hours Of Support</p>-->
<!--            </div>-->
<!--          </div>&lt;!&ndash; End Stats Item &ndash;&gt;-->

<!--          <div class="col-lg-3 col-md-6">-->
<!--            <div class="stats-item text-center w-100 h-100">-->
<!--              <span data-purecounter-start="0" data-purecounter-end="32" data-purecounter-duration="1" class="purecounter"></span>-->
<!--              <p>Workers</p>-->
<!--            </div>-->
<!--          </div>&lt;!&ndash; End Stats Item &ndash;&gt;-->

<!--        </div>-->

<!--      </div>-->

<!--    </section>&lt;!&ndash; /Stats Section &ndash;&gt;-->

    <!-- Services Section -->
    <section id="date" class="date section">

      <!-- Section Title -->
      <div class="container section-title" data-aos="fade-up">
        <h2>Important Dates</h2>
<!--        <p>Necessitatibus eius consequatur ex aliquid fuga eum quidem sint consectetur velit</p>-->
      </div><!-- End Section Title -->


      <div class="container">
          <div class="gy-2 row">
            <p>All deadlines are specified in AoE (Anywhere on Earth).
            </p>

            <b style="color: #0d6efd">[Workshop Timeline]
            </b>
              <div class="col-lg-8 col-12">
                  <table class="table table-borderless">
                      <tbody>
<!--                          <tr>-->
<!--                              <th>December 25, 2024</th>-->
<!--                              <td>First call for workshop papers</td>-->
<!--                          </tr>-->

<!--                          <tr>-->
<!--                              <th>January 24, 2025</th>-->
<!--                              <td>Second call for workshop papers</td>-->
<!--                          </tr>-->
<!--                          <tr>-->
<!--                              <th>February 10, 2025</th>-->
<!--                              <td>Training data and participant instruction release for all shared tasks</td>-->
<!--                          </tr>-->
<!--                          <tr>-->
<!--                              <th>February 24, 2025</th>-->
<!--                              <td>Third call for workshop papers</td>-->
<!--                          </tr>-->
                          <tr>
<!--                              <th style="color: red;"><del style="color: black;">May 17</del> May 31, 2025</th>-->
                              <th>March 18, 2025</th>
                              <td>Direct workshop paper submission deadline</td>
                          </tr>

                          <tr>
                              <th>March 25, 2025</th>
                              <td>ARR pre-reviewed workshop paper commitment deadline</td>
                          </tr>

                          <tr>
                              <th >April 5, 2025</th>
                              <td>Notification of all shared tasks</td>
                          </tr>

                          <tr>
                              <th>April 30, 2025</th>
                              <td>Acceptance notification of all papers</td>
                          </tr>
                          <tr>
                              <th >May 16, 2025</th>
                              <td>Camera ready paper deadline</td>
                          </tr>

<!--                          <tr>-->
<!--                              <th>June 30, 2025</th>-->
<!--                              <td>Proceedings due (hard deadline)</td>-->
<!--                          </tr>-->


                          <tr>
                              <th>July 7, 2025</th>
                              <td>Pre-recorded video due (hard deadline)</td>
                          </tr>


                          <tr>
                              <th>July 31st - August 1st 2025</th>
                              <td>Workshop dates (TBD)</td>
                          </tr>


                      </tbody>
                  </table>
              </div>


            <b style="color: #07b24b;margin-top: 10px">[Shared Task Timeline]
            </b>
              <div class="col-lg-8 col-12">
                  <table class="table table-borderless">
                      <tbody>
                          <tr>
                              <th>February 10, 2025</th>
                              <td>Training data and participant instruction release for all shared tasks</td>
                          </tr>

                          <tr>
                              <th >March 30, 2025</th>
                              <td>Evaluation deadline for all shared tasks</td>
                          </tr>
                          <tr>
                              <th >April 5, 2025</th>
                              <td>Notification of all shared tasks</td>
                          </tr>
                          <tr>
                              <th>April 12, 2025</th>
                              <td>Shared-task paper submission deadline</td>
                          </tr>

                          <tr>
                              <th>April 30, 2025</th>
                              <td>Acceptance notification of shared-task papers</td>
                          </tr>
                          <tr>
                              <th >May 16, 2025</th>
                              <td>Camera ready paper deadline</td>
                          </tr>

                      </tbody>
                  </table>
              </div>

          </div>
      </div>




    </section><!-- /Services Section -->

    <!-- Features Section -->
    <section id="call" class="call section">

      <!-- Section Title -->
      <div class="container section-title" data-aos="fade-up">
        <h2>Call for Papers</h2>
<!--        <p>Necessitatibus eius consequatur ex aliquid fuga eum quidem sint consectetur velit</p>-->
      </div><!-- End Section Title -->

      <div class="container">

        <h3 style="font-weight: 700; font-size: 32px;">Topics</h3>
        <div class="row gy-4">
          <p style="margin-top: 60px;margin-bottom: -10px">We welcome paper submissions on all topics related to structure modeling under LLMs, including but not limited to:
          </p>
          <ul style="padding-left: 40px;line-height: 1.8;">
            <li><b style="font-size: large">LLM for Structure Modeling (LLM4X)</b></li>
            <ul>
                <li><b>Low-level Syntactic Parsing and Methods</b></li>
                    <ul>
                        <li>Morphological Parsing</li>
                        <li>Dependency Parsing/Constituency Parsing</li>
                        <li>Low-resource/Cross-lingual Syntactic Parsing</li>
                        <li>Head-driven Phrase Structure Grammar Parsing</li>
                        <li>Unsupervised Grammar Induction</li>
                        <li>Cross-modal Parsing/Vision-Language Grammar Induction</li>
                    </ul>

                <li><b>High-level Semantic Parsing and Methods</b></li>
                    <ul>
                        <li>Semantic Dependency Parsing</li>
                        <li>Frame Parsing</li>
                        <li>Semantic Role Labeling</li>
                        <li>Abstract Meaning Representation</li>
                        <li>Uniform Meaning Representation</li>
                        <li>Universal Decompositional Semantic Parsing</li>
                        <li>Universal Conceptual Cognitive Annotation</li>
                        <li>Rhetorical Structure Theory (RST) Parsing</li>
                        <li>Conversation Discourse Parsing</li>
                        <li>Low-resource/Cross-lingual Semantic Parsing</li>
                    </ul>

                <li><b>Broader Structure-aware Applications and Methods</b></li>
                    <ul>
                        <li>Information Extraction (IE): NER, RE, EE</li>
                        <li>Structured Sentiment Analysis (SSA), Aspect-based Sentiment Analysis (ABSA)</li>
                        <li>Low-resource/Cross-lingual IE/SSA/ABSA/</li>
                        <li>Cross-modal IE/SSA/ABSA/</li>
                        <li>Text-to-SQL</li>
                        <li>Table Parsing</li>
                        <li>Document Parsing</li>
                        <li>Scene Graph Parsing</li>
                        <li>Universal Structure Parsing/Modeling</li>
                        <li>Human-centered Parsing with LLM</li>
                        <li>Robustness Analysis of LLM-based Parsing</li>
                    </ul>

            </ul>

            <li style="margin-top: 20px"><b  style="font-size: large">Structure Modeling for LLM (X4LLM)</b></li>
            <ul>
                <li>Linguistic and/or mathematical arguments for or against the utility of linguistic structures in language models</li>
                <li>Empirical studies of the utility of linguistic structures in language models</li>
                <li>Integration of various types of linguistic structures into transformers or other architectures underlying modern language models</li>
                <li>Incorporation of linguistic structures and representations as additional input or output in language modeling</li>
                <li>Incorporation of training signals from linguistic structures in language model pre-training and post-training</li>
                <li>Language model prompting with linguistic rules and structural information</li>
                <li>Analyses and interpretation of transformers and language models through the lens of linguistic structures</li>
            </ul>
          </ul>


        </div>


      <div class="container" style="margin-top: 40px">

        <h3 style="font-weight: 700; font-size: 32px;">Paper Submission Information</h3>
        <div class="row gy-4">
          <p style="margin-top: 40px;margin-bottom: -10px">We welcome two types of papers: regular papers and non-archival extended abstracts.
              All submissions must follow <a href="https://aclrollingreview.org/cfp#paper-submission-information">the format requirement of ACL/ARR</a>, and made through OpenReview.
          </p>
          <ul style="padding-left: 40px;">
            <li><b>Regular workshop papers:</b>
            <p style="text-align: justify">Authors can submit papers up to 8 pages, with unlimited pages for references. Authors may submit up to 100 MB of supplementary materials separately and their code for reproducibility. All submissions undergo a double-blind single-track review.
              We will set <b style="color: #dc3545">Best Paper Award(s)</b>, which will be given based on nomination by the reviewers.
              Accepted papers will be presented as posters with the possibility of oral presentations, and will be included in the workshop proceedings.</p>
            </li>

            <li style="margin-top: 10px"><b>Non-archival</b> extended abstracts:
            <p style="text-align: justify">Cross-submissions are welcome.
              Authors can submit extended abstracts up to 6 pages (short) to 8 pages (long), with unlimited pages for references. An extended abstract may report on work in progress or work that has already appeared in or been accepted by another venue within two years before the workshop. It does not need to be anonymized, but should state explicitly where it was originally accepted or published. Accepted extended abstracts will be presented as posters and will not be included in the workshop proceedings.</p></li>

          </ul>

          <p style="margin-top: -20px;text-align: justify">In addition to papers submitted directly to the workshop, which will be reviewed by our Programme Committee, we also accept papers reviewed through ACL Rolling Review and committed to the workshop. Please check the relevant dates for each type of submission.
          </p>


          <div class="container" data-aos="fade-up" style="
            align-content: flex-start;
            display: flex;
            flex-direction: row;
            flex-wrap: nowrap;
            justify-content: center;">
            <div >

            <div class="row gy-2" style="
              display: flex;
              justify-content: space-between;
              flex-wrap: nowrap;
              flex-direction: row;">
                <blockquote style="width: fit-content;margin-right: 100px;">
                  <button type="button" class="btn  btn-outline-dark "><a href="https://openreview.net/group?id=aclweb.org/ACL/2025/Workshop/XLLM"><b class="text-danger">Entry for Regular Submission</b></a></button>
                </blockquote>


                <blockquote>
                  <button type="button" class="btn  btn-outline-dark "><a href="https://openreview.net/group?id=aclweb.org/ACL/2025/Workshop/XLLM_ARR_Commitment"><b class="text-danger">Entry for ARR Pre-reviewed Commitment</b></a></button>
                </blockquote>

            </div>
            </div>
          </div>

        </div>


<!--        <div class="row gy-4 align-items-center features-item">-->
<!--          <div class="col-lg-5 order-2 order-lg-1" data-aos="fade-up" data-aos-delay="200">-->
<!--            <h3>Corporis temporibus maiores provident</h3>-->
<!--            <p>-->
<!--              Ullamco laboris nisi ut aliquip ex ea commodo consequat. Duis aute irure dolor in reprehenderit in voluptate-->
<!--              velit esse cillum dolore eu fugiat nulla pariatur. Excepteur sint occaecat cupidatat non proident.-->
<!--            </p>-->
<!--            <a href="#" class="btn btn-get-started">Get Started</a>-->
<!--          </div>-->
<!--          <div class="col-lg-7 order-1 order-lg-2 d-flex align-items-center" data-aos="zoom-out" data-aos-delay="100">-->
<!--            <div class="image-stack">-->
<!--              <img src="assets/img/features-light-1.jpg" alt="" class="stack-front">-->
<!--              <img src="assets/img/features-light-2.jpg" alt="" class="stack-back">-->
<!--            </div>-->
<!--          </div>-->
<!--        </div>&lt;!&ndash; Features Item &ndash;&gt;-->

<!--        <div class="row gy-4 align-items-stretch justify-content-between features-item ">-->
<!--          <div class="col-lg-6 d-flex align-items-center features-img-bg" data-aos="zoom-out">-->
<!--            <img src="assets/img/features-light-3.jpg" class="img-fluid" alt="">-->
<!--          </div>-->
<!--          <div class="col-lg-5 d-flex justify-content-center flex-column" data-aos="fade-up">-->
<!--            <h3>Sunt consequatur ad ut est nulla</h3>-->
<!--            <p>Cupiditate placeat cupiditate placeat est ipsam culpa. Delectus quia minima quod. Sunt saepe odit aut quia voluptatem hic voluptas dolor doloremque.</p>-->
<!--            <ul>-->
<!--              <li><i class="bi bi-check"></i> <span>Ullamco laboris nisi ut aliquip ex ea commodo consequat.</span></li>-->
<!--              <li><i class="bi bi-check"></i><span> Duis aute irure dolor in reprehenderit in voluptate velit.</span></li>-->
<!--              <li><i class="bi bi-check"></i> <span>Facilis ut et voluptatem aperiam. Autem soluta ad fugiat</span>.</li>-->
<!--            </ul>-->
<!--            <a href="#" class="btn btn-get-started align-self-start">Get Started</a>-->
<!--          </div>-->
<!--        </div>&lt;!&ndash; Features Item &ndash;&gt;-->

      </div>

    </section><!-- /Features Section -->















    <!-- Team Section -->
    <section id="keynote" class="keynote section">

      <!-- Section Title -->
      <div class="container section-title" data-aos="fade-up">
        <h2>Invited Keynote Speakers</h2>
<!--        <p>Necessitatibus eius consequatur ex aliquid fuga eum quidem sint consectetur velit</p>-->
      </div><!-- End Section Title -->


      <div class="container">
          <p style="color: red;font-size: large;font-weight: bold;">- TBD -</p>
      </div>




      <div class="container">

          <div class="row py-4 px-lg-3 px-0">
              <div class="col-12 col-md-4 col-lg-2 mx-lg-2 order-first" style="display: flex;flex-direction: row;flex-wrap: nowrap;align-content: flex-start;justify-content: center;">
                  <div style="display: flex;justify-content: center;flex-direction: column;">
                      <a href="https://web.science.mq.edu.au/~mjohnson/"><img src="./assets/img/speaker/Mark-Johnson.jpg" class="d-block m-2 rounded card-img-top" loading="lazy" style="width:250px;"></a>
                  </div>
              </div>
              <div class="col mx-5">
                  <a href="https://web.science.mq.edu.au/~mjohnson/"><h4 class="text-center text-md-start">Mark Johnson</h4></a>
                  <p class="text-center text-md-start"><small>Professor at Macquarie University</small></p>
                  <p style="text-align: justify"><b>Bio:</b> [TBD] Mark Johnson is a Professor of Language Science (CORE) in the School of Computing at Macquarie University. He is also the Chief AI Scientist, Oracle Digital Assistant at Oracle Corporation, where he develops chatbots and digital assistants. The Oracle Digital Assistant division develops novel deep learning models to power the next generation of Conversational AI using semantic parsing.
                Mark Johnson has worked on a wide range of topics in computational linguistics, but his main area of research is natural language understanding, especially syntactic parsing and semantic analysis, and their applications to text and speech processing.
                  </p>
                  <p><b>Title:</b> <u class="fw-normal"> [TDB]</u></p>
                  <p style="text-align: justify"><b>Abstract:</b> [TDB]
                  </p>
              </div>
          </div>
      </div>



      <div class="container" style="margin-top: 40px">

          <div class="row py-4 px-lg-3 px-0">
              <div class="col-12 col-md-4 col-lg-2 mx-lg-2 order-first" style="display: flex;flex-direction: row;flex-wrap: nowrap;align-content: flex-start;justify-content: center;">
                  <div style="display: flex;justify-content: center;flex-direction: column;">
                      <a href="https://mariannaapi.github.io/"><img src="./assets/img/speaker/Jan-Hajiƒç.jpg" class="d-block m-2 rounded card-img-top" loading="lazy" style="width:250px;"></a>
                  </div>
              </div>
              <div class="col mx-5">
                  <a href="https://mariannaapi.github.io/"><h4 class="text-center text-md-start" >Jan Hajiƒç</h4></a>
                  <p class="text-center text-md-start"><small>Professor at Charles University</small></p>
                  <p style="text-align: justify"><b>Bio:</b> Jan Hajiƒç is a professor of Computational Linguistics at the Institute of Formal and Applied Linguistics, School of Computer Science, Charles University, Prague, Czechia. His interests span fundamental formal linguistic problems, machine translation, deep language understanding, and applications. He has built resources for many languages with rich linguistic annotation, such as the Prague Dependency Treebank; he is currently leading a multi-institutional research infrastructure on language resources in Czechia, LINDAT/CLARIAH-CZ, and coordinating a Horizon Europe pilot project on building LLMs, HPLT. His work experience includes both industrial research (IBM Research Yorktown Heights, NY, USA) and academia (Charles University, Prague, Czechia, Johns Hopkins University and University of Colorado, USA, Fellow of the Centre for Advanced Studies at the Norway Academy of Sciences, and others). He has published more than 200 papers. He is a chair or member of many international and national boards and committees, such as the Steering Committee of the TACL journal.
                  </p>
                  <p><b>Title:</b> <u class="fw-normal"> [TDB]</u></p>
                  <p style="text-align: justify"><b>Abstract:</b> [TDB]
                  </p>
              </div>
          </div>
      </div>



      <div class="container" style="margin-top: 40px">

          <div class="row py-4 px-lg-3 px-0">
              <div class="col-12 col-md-4 col-lg-2 mx-lg-2 order-first" style="display: flex;flex-direction: row;flex-wrap: nowrap;align-content: flex-start;justify-content: center;">
                  <div style="display: flex;justify-content: center;flex-direction: column;">
                      <a href="https://blender.cs.illinois.edu/hengji.html"><img src="./assets/img/speaker/Prof. Heng Ji.jpg" class="d-block m-2 rounded card-img-top" loading="lazy" style="width:250px;"></a>
                  </div>
              </div>
              <div class="col mx-5">
                  <a href="https://blender.cs.illinois.edu/hengji.html"><h4 class="text-center text-md-start" >Heng Ji</h4></a>
                  <p class="text-center text-md-start"><small>Professor at University of Illinois Urbana-Champaign</small></p>
                  <p style="text-align: justify"><b>Bio:</b> Heng Ji is a professor at the Computer Science Department and an affiliated faculty member at the Electrical and Computer Engineering Department and Coordinated Science Laboratory of the University of Illinois Urbana-Champaign.
                      She is an Amazon Scholar. She is the Founding Director of the Amazon-Illinois Center on AI for Interactive Conversational Experiences (AICE).
                      Her research interests focus on Natural Language Processing, especially on Multimedia Multilingual Information Extraction, Knowledge-enhanced Large Language Models and Vision-Language Models.
                      She was selected as a "Young Scientist" by the World Laureates Association in 2023 and 2024. She was selected as a "Young Scientist" and a member of the Global Future Council on the Future of Computing by the World Economic Forum in 2016 and 2017.
<!--                      She was named as part of Women Leaders of Conversational AI (Class of 2023) by Project Voice. -->
                      The other awards she received include two Outstanding Paper Awards at NAACL2024, "AI's 10 to Watch" Award by IEEE Intelligent Systems in 2013, NSF CAREER award in 2009, PACLIC2012 Best Paper runner-up, "Best of ICDM2013" paper award, "Best of SDM2013" paper award, ACL2018 Best Demo paper nomination, ACL2020 Best Demo Paper Award, NAACL2021 Best Demo Paper Award, Google Research Award in 2009 and 2014, IBM Watson Faculty Award in 2012 and 2014 and Bosch Research Award in 2014-2018.
<!--                      She was invited to testify to the U.S. House Cybersecurity, Data Analytics, & IT Committee as an AI expert in 2023. She was selected to participate in DARPA AI Forward in 2023. -->
<!--                      She was invited by the Secretary of the U.S. Air Force and AFRL to join the Air Force Data Analytics Expert Panel to inform the Air Force Strategy 2030, and invited to speak at the Federal Information Integrity R&D Interagency Working Group (IIRD IWG) briefing in 2023. -->
<!--                      She is the lead of many multi-institution projects and tasks, including the U.S. ARL projects on information fusion and knowledge networks construction, DARPA ECOLE MIRACLE team, DARPA KAIROS RESIN team and DARPA DEFT Tinker Bell team. -->
<!--                      She has coordinated the NIST TAC Knowledge Base Population Task 2010-2020. She is the Chief Editor of Data Intelligence Journal. -->
                      She served as the associate editor for IEEE/ACM Transaction on Audio, Speech, and Language Processing, and the Program Committee Co-Chair of many conferences including NAACL-HLT2018 and AACL-IJCNLP2022.
                      She was elected as the secretary of the North American Chapter of the Association for Computational Linguistics (NAACL) 2020-2023.
                      Her research has been widely supported by the U.S. government agencies (DARPA, NSF, DoE, ARL, IARPA, AFRL, DHS) and industry (Amazon, Google, Bosch, IBM, Disney).
                  </p>
                  <p><b>Title:</b> <u class="fw-normal"> Never-Ending Wikipedia Updating</u></p>
                  <p style="text-align: justify"><b>Abstract:</b> [TDB]
                  </p>
              </div>
          </div>
      </div>

      <div class="container">

          <div class="row py-4 px-lg-3 px-0">
              <div class="col-12 col-md-4 col-lg-2 mx-lg-2 order-first" style="display: flex;flex-direction: row;flex-wrap: nowrap;align-content: flex-start;justify-content: center;">
                  <div style="display: flex;justify-content: center;flex-direction: column;">
                      <a href="https://www.cs.brandeis.edu/~xuen/"><img src="./assets/img/speaker/nianwen-xue.jpg" class="d-block m-2 rounded card-img-top" loading="lazy" style="width:250px;"></a>
                  </div>
              </div>
              <div class="col mx-5">
                  <a href="https://www.cs.brandeis.edu/~xuen/"><h4 class="text-center text-md-start">Nianwen Xue</h4></a>
                  <p class="text-center text-md-start"><small>Professor at Brandeis University</small></p>
                  <p style="text-align: justify"><b>Bio:</b> [TDB] Nianwen Xue is a Professor at Brandeis University. He directs the Chinese Language Processing Group in the Computer Science Department and the Language & Linguistics Program. His research interests include developing linguistic corpora annotated with Syntactic, Semantic, and Discourse Structures, as well as Machine Learning approaches to Syntactic, Semantic and Discourse Parsing. He is the co-founder of various linguistic corpora and projects, such as CPB, SRL and OntoNotes. His research has been funded by NSF, DARPA, and IARPA. He served as the Editor-in-Chief of TALLIP and currently serves on the editorial boards of LRE, and Lingua Sinica.
                  </p>
                  <p><b>Title:</b> <u class="fw-normal">Uniform Meaning Representation</u></p>
                  <p style="text-align: justify"><b>Abstract:</b> [TDB]  One of the frequent points in the mainstream narrative about large language
                      models is that they have emergent properties", but there is a lot of disagreement about what
                      that even means. If they are understood as a kind of generalization beyond training data- as
                      something that a model does without being explicitly trained for it- I argue that we have
                      not in fact established the existence of any such properties, and at the moment we do not
                      even have the methodology for doing so.
                  </p>
              </div>
          </div>
      </div>



      <div class="container">

          <div class="row py-4 px-lg-3 px-0">
              <div class="col-12 col-md-4 col-lg-2 mx-lg-2 order-first" style="display: flex;flex-direction: row;flex-wrap: nowrap;align-content: flex-start;justify-content: center;">
                  <div style="display: flex;justify-content: center;flex-direction: column;">
                      <a href="https://scottyih.org/"><img src="./assets/img/speaker/Scott-Yih.jpg" class="d-block m-2 rounded card-img-top" loading="lazy" style="width:250px;"></a>
                  </div>
              </div>
              <div class="col mx-5">
                  <a href="https://scottyih.org/"><h4 class="text-center text-md-start">Scott Yih</h4></a>
                  <p class="text-center text-md-start"><small>Scientist at Facebook AI Research (FAIR)</small></p>
                  <p style="text-align: justify"><b>Bio:</b>
                      Scott Wen-tau Yih is a Research Scientist at Facebook AI Research (FAIR).
                      He was elected as ACL Fellow in 2024.
                      His research interests include natural language processing, machine learning and information retrieval.
<!--                      Yih received his Ph.D. in computer science at the University of Illinois at Urbana-Champaign. -->
                      His work on joint inference using integer linear programming (ILP) has been widely adopted in the NLP community for numerous structured prediction problems.
                      Before joining FAIR, Yih was a Principal Research Scientist at the Allen Institute for Artificial Intelligence (AI2), working on scientific question answering.
                      Prior to that, Yih had spent 12 years at Microsoft Research, working on a variety of projects including email spam filtering, keyword extraction and search & ad relevance.
                      His recent work focuses on continuous representations and neural network models, with applications in knowledge base embedding, semantic parsing and question answering.
                      Yih received the best paper award from CoNLL-2011, an outstanding paper award from ACL-2015 and has served as area co-chairs (HLT-NAACL-12, ACL-14, EMNLP-16,17,18),
                      program co-chairs (CEAS-09, CoNLL-14) and action/associated editors (TACL, JAIR) in recent years.
<!--                      He is also a co-presenter for several tutorials on topics including Semantic Role Labeling (NAACL-HLT-06, AAAI-07), -->
<!--                      Deep Learning for NLP (SLT-14, NAACL-HLT-15, IJCAI-16), NLP for Precision Medicine (ACL-17).-->
                  </p>
                  <p><b>Title:</b> <u class="fw-normal">[TDB]</u></p>
                  <p style="text-align: justify"><b>Abstract:</b> [TDB]
                  </p>
              </div>
          </div>
      </div>





<!--      <div class="container">-->

<!--          <div class="row py-4 px-lg-3 px-0">-->
<!--              <div class="col-12 col-md-4 col-lg-2 mx-lg-2 order-first" style="display: flex;flex-direction: row;flex-wrap: nowrap;align-content: flex-start;justify-content: center;">-->
<!--                  <div style="display: flex;justify-content: center;flex-direction: column;">-->
<!--                      <a href="#"><img src="./assets/img/team/team-2.jpg" class="d-block m-2 rounded card-img-top" loading="lazy" style="width:250px;"></a>-->
<!--                  </div>-->
<!--              </div>-->
<!--              <div class="col mx-5">-->
<!--                  <a href="#"><h4 class="text-center text-md-start">TBD</h4></a>-->
<!--                  <p class="text-center text-md-start"><small>TBD</small></p>-->
<!--                  <p style="text-align: justify"><b>Bio:</b> One of the frequent points in the mainstream narrative about large language-->
<!--                      models is that they have emergent properties", but there is a lot of disagreement about what-->
<!--                      that even means. If they are understood as a kind of generalization beyond training data- as-->
<!--                      something that a model does without being explicitly trained for it- I argue that we have-->
<!--                      not in fact established the existence of any such properties.-->
<!--                  </p>-->
<!--                  <p><b>Title:</b> <u class="fw-normal"> TBD</u></p>-->
<!--                  <p style="text-align: justify"><b>Abstract:</b> TBD.-->
<!--                  </p>-->
<!--              </div>-->
<!--          </div>-->
<!--      </div>-->







<!--      <div class="container" style="margin-top: 40px">-->

<!--          <div class="row py-4 px-lg-3 px-0">-->
<!--              <div class="col-12 col-md-4 col-lg-2 mx-lg-2 order-first" style="display: flex;flex-direction: row;flex-wrap: nowrap;align-content: flex-start;justify-content: center;">-->
<!--                  <div style="display: flex;justify-content: center;flex-direction: column;">-->
<!--                      <img src="./assets/img/team/team-3.jpg" class="d-block m-2 rounded card-img-top" loading="lazy" style="width:250px;">-->
<!--                  </div>-->
<!--              </div>-->
<!--              <div class="col mx-5">-->
<!--                  <h4 class="text-center text-md-start">Anna Rogers</h4>-->
<!--                  <p class="text-center text-md-start"><small>Associate Professor at IT University of-->
<!--                          Copenhagen</small></p>-->
<!--                  <p><b>Bio:</b> One of the frequent points in the mainstream narrative about large language-->
<!--                      models is that they have emergent properties", but there is a lot of disagreement about what-->
<!--                      that even means. If they are understood as a kind of generalization beyond training data- as-->
<!--                      something that a model does without being explicitly trained for it- I argue that we have-->
<!--                      not in fact established the existence of any such properties.-->
<!--                  </p>-->
<!--                  <p><b>Title:</b> <u class="fw-normal">A Sanity Check on Emergent Properties.</u></p>-->
<!--                  <p><b>Abstract:</b> One of the frequent points in the mainstream narrative about large language-->
<!--                      models is that they have emergent properties", but there is a lot of disagreement about what-->
<!--                      that even means. If they are understood as a kind of generalization beyond training data- as-->
<!--                      something that a model does without being explicitly trained for it- I argue that we have-->
<!--                      not in fact established the existence of any such properties, and at the moment we do not-->
<!--                      even have the methodology for doing so.-->
<!--                  </p>-->
<!--              </div>-->
<!--          </div>-->
<!--      </div>-->




<!--      <div class="container" style="margin-top: 40px">-->

<!--          <div class="row py-4 px-lg-3 px-0">-->
<!--              <div class="col-12 col-md-4 col-lg-2 mx-lg-2 order-first" style="display: flex;flex-direction: row;flex-wrap: nowrap;align-content: flex-start;justify-content: center;">-->
<!--                  <div style="display: flex;justify-content: center;flex-direction: column;">-->
<!--                      <img src="./assets/img/team/team-4.jpg" class="d-block m-2 rounded card-img-top" loading="lazy" style="width:250px;">-->
<!--                  </div>-->
<!--              </div>-->
<!--              <div class="col mx-5">-->
<!--                  <h4 class="text-center text-md-start">Anna Rogers</h4>-->
<!--                  <p class="text-center text-md-start"><small>Associate Professor at IT University of-->
<!--                          Copenhagen</small></p>-->
<!--                  <p><b>Bio:</b> One of the frequent points in the mainstream narrative about large language-->
<!--                      models is that they have emergent properties", but there is a lot of disagreement about what-->
<!--                      that even means. If they are understood as a kind of generalization beyond training data- as-->
<!--                      something that a model does without being explicitly trained for it- I argue that we have-->
<!--                      not in fact established the existence of any such properties.-->
<!--                  </p>-->
<!--                  <p><b>Title:</b> <u class="fw-normal">A Sanity Check on Emergent Properties.</u></p>-->
<!--                  <p><b>Abstract:</b> One of the frequent points in the mainstream narrative about large language-->
<!--                      models is that they have emergent properties", but there is a lot of disagreement about what-->
<!--                      that even means. If they are understood as a kind of generalization beyond training data- as-->
<!--                      something that a model does without being explicitly trained for it- I argue that we have-->
<!--                      not in fact established the existence of any such properties, and at the moment we do not-->
<!--                      even have the methodology for doing so.-->
<!--                  </p>-->
<!--              </div>-->
<!--          </div>-->
<!--      </div>-->




    </section>

















    <!-- Pricing Section -->
    <section id="schedule" class="schedule section">

      <!-- Section Title -->
      <div class="container section-title" data-aos="fade-up">
        <h2>Program Schedule</h2>
<!--        <p>Necessitatibus eius consequatur ex aliquid fuga eum quidem sint consectetur velit</p>-->
      </div><!-- End Section Title -->



      <div class="container">

          <p style="color: red;font-size: large;font-weight: bold;">- TBD -</p>


<!--        <p>The workshop will be located in the room XXX at the ACL2025 conference venue.</p>-->

<!--        <p>The schedule for the workshop is the following:-->
<!--        </p>-->

<!--        <div class="pt-2 row">-->
<!--                    <div class="col-12">-->
<!--                        <table class="table table-borderless">-->
<!--                            <tbody>-->
<!--                                <tr>-->
<!--                                    <th style="width: 125px;">08:55-09:00</th>-->
<!--                                    <td>Opening Remarks</td>-->
<!--                                </tr>-->
<!--                                <tr>-->
<!--                                    <th>09:00-09:45</th>-->
<!--                                    <td><b>Invited talk by Margaret Mitchell:</b> On the value of carefully measuring-->
<!--                                        data.</td>-->
<!--                                </tr>-->
<!--                                <tr>-->
<!--                                    <th>09:45-10:30</th>-->
<!--                                    <td><b>Invited talk by Dieuwke Hupkes:</b> Evaluation data contamination: how much is-->
<!--                                        there, and how-->
<!--                                        much does it actually matter?</td>-->
<!--                                </tr>-->
<!--                                <tr>-->
<!--                                    <th>10:30-11:00</th>-->
<!--                                    <td><i>Break</i></td>-->
<!--                                </tr>-->
<!--                                <tr>-->
<!--                                    <th>11:00-11:45</th>-->
<!--                                    <td><b>Invited talk by Anna Rogers:</b> A Sanity Check on Emergent Properties</td>-->
<!--                                </tr>-->
<!--                                <tr>-->
<!--                                    <th>11:45-12:00</th>-->
<!--                                    <td><b>Best paper presentation:</b> Rethinking LLM Memorization through the Lens of-->
<!--                                        Adversarial Compression</td>-->
<!--                                </tr>-->
<!--                                <tr>-->
<!--                                    <th>12:00-13:30</th>-->
<!--                                    <td><i>Lunch Break</i></td>-->
<!--                                </tr>-->
<!--                                <tr>-->
<!--                                    <th>13:30-15:30</th>-->
<!--                                    <td>Paper Session:</td>-->
<!--                                </tr>-->
<!--                                <tr>-->
<!--                                    <th></th>-->
<!--                                    <td><span class="fw-normal">Title TBD</span><br><small>Author TBD</small>-->
<!--                                    </td>-->
<!--                                </tr>-->
<!--                                <tr>-->
<!--                                    <th></th>-->
<!--                                    <td><span class="fw-normal">Title TBD</span><br><small>Author TBD</small>-->
<!--                                    </td>-->
<!--                                </tr>-->

<!--                                <tr>-->
<!--                                    <th>15:30-16:00</th>-->
<!--                                    <td><i>Break</i></td>-->
<!--                                </tr>-->
<!--                                <tr>-->
<!--                                    <th>16:00-16:45</th>-->
<!--                                    <td><b>Invited talk by Jesse Dodge:</b> Contamination in Web-Scale Datasets and its-->
<!--                                        Impact on Large-->
<!--                                        Model Evaluations</td>-->
<!--                                </tr>-->
<!--                                <tr>-->
<!--                                    <th>17:00-17:15</th>-->
<!--                                    <td>Closing Remarks</td>-->
<!--                                </tr>-->
<!--                            </tbody>-->
<!--                        </table>-->
<!--                    </div>-->
<!--                </div>-->

      </div>


<!--      <div class="container" data-aos="zoom-in" data-aos-delay="100">-->

<!--        <div class="row g-4">-->

<!--          <div class="col-lg-4">-->
<!--            <div class="pricing-item">-->
<!--              <h3>Free Plan</h3>-->
<!--              <div class="icon">-->
<!--                <i class="bi bi-box"></i>-->
<!--              </div>-->
<!--              <h4><sup>$</sup>0<span> / month</span></h4>-->
<!--              <ul>-->
<!--                <li><i class="bi bi-check"></i> <span>Quam adipiscing vitae proin</span></li>-->
<!--                <li><i class="bi bi-check"></i> <span>Nec feugiat nisl pretium</span></li>-->
<!--                <li><i class="bi bi-check"></i> <span>Nulla at volutpat diam uteera</span></li>-->
<!--                <li class="na"><i class="bi bi-x"></i> <span>Pharetra massa massa ultricies</span></li>-->
<!--                <li class="na"><i class="bi bi-x"></i> <span>Massa ultricies mi quis hendrerit</span></li>-->
<!--              </ul>-->
<!--              <div class="text-center"><a href="#" class="buy-btn">Buy Now</a></div>-->
<!--            </div>-->
<!--          </div>&lt;!&ndash; End Pricing Item &ndash;&gt;-->

<!--          <div class="col-lg-4">-->
<!--            <div class="pricing-item featured">-->
<!--              <h3>Business Plan</h3>-->
<!--              <div class="icon">-->
<!--                <i class="bi bi-rocket"></i>-->
<!--              </div>-->

<!--              <h4><sup>$</sup>29<span> / month</span></h4>-->
<!--              <ul>-->
<!--                <li><i class="bi bi-check"></i> <span>Quam adipiscing vitae proin</span></li>-->
<!--                <li><i class="bi bi-check"></i> <span>Nec feugiat nisl pretium</span></li>-->
<!--                <li><i class="bi bi-check"></i> <span>Nulla at volutpat diam uteera</span></li>-->
<!--                <li><i class="bi bi-check"></i> <span>Pharetra massa massa ultricies</span></li>-->
<!--                <li><i class="bi bi-check"></i> <span>Massa ultricies mi quis hendrerit</span></li>-->
<!--              </ul>-->
<!--              <div class="text-center"><a href="#" class="buy-btn">Buy Now</a></div>-->
<!--            </div>-->
<!--          </div>&lt;!&ndash; End Pricing Item &ndash;&gt;-->

<!--          <div class="col-lg-4">-->
<!--            <div class="pricing-item">-->
<!--              <h3>Developer Plan</h3>-->
<!--              <div class="icon">-->
<!--                <i class="bi bi-send"></i>-->
<!--              </div>-->
<!--              <h4><sup>$</sup>49<span> / month</span></h4>-->
<!--              <ul>-->
<!--                <li><i class="bi bi-check"></i> <span>Quam adipiscing vitae proin</span></li>-->
<!--                <li><i class="bi bi-check"></i> <span>Nec feugiat nisl pretium</span></li>-->
<!--                <li><i class="bi bi-check"></i> <span>Nulla at volutpat diam uteera</span></li>-->
<!--                <li><i class="bi bi-check"></i> <span>Pharetra massa massa ultricies</span></li>-->
<!--                <li><i class="bi bi-check"></i> <span>Massa ultricies mi quis hendrerit</span></li>-->
<!--              </ul>-->
<!--              <div class="text-center"><a href="#" class="buy-btn">Buy Now</a></div>-->
<!--            </div>-->
<!--          </div>&lt;!&ndash; End Pricing Item &ndash;&gt;-->

<!--        </div>-->

<!--      </div>-->

    </section><!-- /Pricing Section -->










    <!-- Portfolio Section -->
    <section id="task" class="task section">

      <!-- Section Title -->
      <div class="container section-title" data-aos="fade-up">
        <h2>Shared Tasks</h2>
      </div><!-- End Section Title -->

      <div class="container">

        <p>In addition to paper contributions, we are organizing open challenges on structure-related NLP tasks. Through these shared tasks, we aim to provide a centralized platform for further exploring and advancing traditional or newly-emerged structure-aware tasks.</p>

<!--        <p>We set up three shared tasks:</p>-->
<!--        <ul style="padding-left: 40px;">-->
<!--            <li><b>Task-I:</b> Dialogue-Level Dependency Parsing</li>-->
<!--            <li><b>Task-II:</b> Speech Event Extraction</li>-->
<!--            <li><b>Task-III:</b> Grounded Multimodal Universal Information Extraction</li>-->
<!--            <li><b>Task-IV:</b> xx</li>-->
<!--        </ul>-->

        <p>We have set up three shared tasks as follows.
            Participants can access the respective task pages to learn about the specific participation requirements.
            System submissions will be evaluated using automatic metrics, with a focus on the accuracy and relevance of the results.
            Participants can submit at <a href="https://www.codabench.org/competitions/xxx/">Codabench</a>.
        </p>

        <p>Teams that achieve top rankings in part of the shared tasks will receive cash prizes.
        Winning participants are required to write a technical paper that fully describes the techniques and experimental results used. Additionally, they will need to prepare a poster or oral presentation to showcase their methods and approaches on-site.
        </p>

      </div>



      <div class="container" style="margin-top: 40px">

        <h3 style="font-weight: 700; font-size: 32px;">Task-I: Dialogue-Level Dependency Parsing (DiaDP)</h3>
        <div class="row gy-4">
          <p style="margin-top: 40px;text-align: justify">DiaDP aims to build a unified word-wise dependency tree for dialogue contexts. The tree integrates both inner-EDU dependencies (within Elementary Discourse Units, EDUs) and inter-EDU dependencies (across EDUs) to represent the syntactic and discourse relationships between words in dialogues.
            Given a dialogue consisting of multiple utterances segmented into EDUs, where each utterance is treated as a sentence-like unit, DiaDP outputs a structured dependency tree that includes:
            1) Inner-EDU dependencies: Syntactic relationships within individual EDUs;
            2) Inter-EDU dependencies: Discourse relationships connecting different EDUs, including cross-utterance links.
            We set zero-shot and few-shot learning settings, respectively.
          </p>
          <p style="margin-top: 0px;margin-bottom: -10px;text-align: justify">
              The task bridges the gap between sentence-level dependency parsing and discourse-level parsing by extending syntactic tree structures to dialogue scenarios; incorporating both rhetorical and syntactic elements into the tree.
<!--              We will set <b style="color: #dc3545">cash prizes</b> for -->
              Top-3 teams will receive a certificate for their performance, and will be invited to write technical papers to be included into workshop proceedings.
            For more details to participate, visit the <a href="https://xllms.github.io/DiaDP">DiaDP challenge website</a>.
          </p>

        </div>

      </div>


      <div class="container" style="margin-top: 40px">

        <h3 style="font-weight: 700; font-size: 32px;">Task-II: Speech Event Extraction (SpeechEE)</h3>
        <div class="row gy-4">
          <p style="margin-top: 40px;text-align: justify">
              SpeechEE aims to detect event predicates and arguments directly from audio speech, enabling information acquisition from spoken content such as meetings, interviews, and press releases.
                The SpeechEE is defined as: Given a speech audio input consisting of a sequence of acoustic frames, the goal is to extract structured event records comprising four elements: 1) the event type, 2) the event trigger, 3) event argument roles, and 4) the corresponding event arguments.
          </p>
          <p style="margin-top: 0px;margin-bottom: -10px;text-align: justify">
              This task bridges the gap between traditional textual event extraction and real-world speech scenarios, providing a foundation for structured knowledge extraction from audio data.
<!--              We will set <b style="color: #dc3545">cash prizes</b> for top three teams.-->
              Top-3 teams will receive a certificate for their performance, and will be invited to write technical papers to be included into workshop proceedings.
            For more details to participate, visit the <a href="https://xllms.github.io/SpeechEE">SpeechEE challenge website</a>.
          </p>

        </div>

      </div>



      <div class="container" style="margin-top: 40px">
        <h3 style="font-weight: 700; font-size: 32px;">Task-III: LLM for Structural Reasoning (LLM-SR)</h3>
        <div class="row gy-4">
          <p style="margin-top: 40px;text-align: justify">
              LLM-SR seeks to generate a controllable and interpretable reasoning process by leveraging structural reasoning. LLM-SR requires the structural parsing of two distinct components: major premises and minor premises, then involving identifying fine-grained ‚Äúalignments‚Äù between these two structures and ultimately deriving a conclusion.
          </p>
          <p style="margin-top: 0px;margin-bottom: -10px;text-align: justify">
              This task can be regarded as a constrained Chain-of-Thought (CoT) reasoning process, where reasoning is conducted step by step with reference to facts and relevant rules, thereby improving the transparency and reliability of the process.
              <b style="color: #dc3545">Cash prizes</b> will be awarded to the top three teams.
            For more details to participate, visit the <a href="https://xllms.github.io/LLMSR">LLM-SR challenge website</a>.
          </p>

        </div>

      </div>




      <div class="container" style="margin-top: 40px">
        <h3 style="font-weight: 700; font-size: 32px;">Task-IV: Document-level Information Extraction (DocIE)</h3>
        <div class="row gy-4">
          <p style="margin-top: 40px;text-align: justify">
              DocIE focuses on extracting information from long documents rather than isolated sentences, necessitating the integration of information both within and across multiple sentences while capturing complex interactions. Given a document and a predefined schema, DocIE requires the extraction of each instance (which may be null) corresponding to the schema's elements. This process involves identifying: (1) types of entities, (2) coreference relationships among mentions, (3) types of relations, and (4) the head and tail entities of each identified relation.
          </p>
          <p style="margin-top: 0px;margin-bottom: -10px;text-align: justify">
              This task evaluates the ability of large language models (LLMs) to extract information from long-context documents and comprehend abstract concepts, thereby advancing their application in mining critical, domain-specific information across various fields.
              <b style="color: #dc3545">Cash prizes</b> will be awarded to the top three teams.
            For more details to participate, visit the <a href="https://xllms.github.io/DocIE">DocIE challenge website</a>.
          </p>

        </div>

      </div>




    </section><!-- /Portfolio Section -->














    <!-- Team Section -->
    <section id="organizer" class="team section">

      <!-- Section Title -->
      <div class="container section-title" data-aos="fade-up">
        <h2>Organization Team</h2>
<!--        <p>Necessitatibus eius consequatur ex aliquid fuga eum quidem sint consectetur velit</p>-->
      </div><!-- End Section Title -->



      <div class="container">

        <div class="row gy-5">

          <div class="col-lg-4 col-md-6 member" data-aos="fade-up" data-aos-delay="100">
            <div class="member-img">
              <a href="https://haofei.vip/"><img src="https://haofei.vip/images/teampic/feihao-potriat.jpg" class="img-fluid" alt="https://haofei.vip/"></a>
            </div>
            <div class="member-info text-center">
              <a href="https://haofei.vip/"><h4>Hao Fei</h4></a>
              <span>National University of Singapore</span>
<!--              <p>Aliquam iure quaerat voluptatem praesentium possimus unde laudantium vel dolorum distinctio dire flow</p>-->
            </div>
          </div><!-- End Team Member -->

          <div class="col-lg-4 col-md-6 member" data-aos="fade-up" data-aos-delay="200">
            <div class="member-img">
              <a href="https://faculty.sist.shanghaitech.edu.cn/faculty/tukw/"><img src="assets/img/organizer/Kewei.jpg" class="img-fluid" alt="ShanghaiTech University"></a>
            </div>
            <div class="member-info text-center">
              <a href="https://faculty.sist.shanghaitech.edu.cn/faculty/tukw/"><h4>Kewei Tu</h4></a>
              <span>ShanghaiTech University</span>
            </div>
          </div><!-- End Team Member -->

        <div class="col-lg-4 col-md-6 member" data-aos="fade-up" data-aos-delay="200">
          <div class="member-img">
            <a href="https://cs.stanford.edu/~yuhuiz/"><img src="assets/img/organizer/yuhuiz.jpeg" class="img-fluid" alt="ShanghaiTech University"></a>
          </div>
          <div class="member-info text-center">
            <a href="https://cs.stanford.edu/~yuhuiz/"><h4>Yuhui Zhang</h4></a>
            <span>Stanford University</span>
          </div>
        </div><!-- End Team Member -->


          <div class="col-lg-4 col-md-6 member" data-aos="fade-up" data-aos-delay="300">
            <div class="member-img">
            <a href="https://imhuim982.github.io/"><img src="assets/img/organizer/Xiang-Hu.jpg" class="img-fluid" alt="ShanghaiTech University"></a>
            </div>
            <div class="member-info text-center">
            <a href="https://imhuim982.github.io/"><h4>Xiang Hu</h4></a>
              <span>Ant Research</span>
            </div>
          </div><!-- End Team Member -->



          <div class="col-lg-4 col-md-6 member" data-aos="fade-up" data-aos-delay="300">
            <div class="member-img">
            <a href="https://winniehan.github.io/"><img src="assets/img/organizer/Wenjuan.png" class="img-fluid" alt="ShanghaiTech University"></a>
            </div>
            <div class="member-info text-center">
            <a href="https://winniehan.github.io/"><h4>Wenjuan Han</h4></a>
              <span>Beijing Jiaotong University</span>
            </div>
          </div><!-- End Team Member -->





          <div class="col-lg-4 col-md-6 member" data-aos="fade-up" data-aos-delay="300">
            <div class="member-img">
            <a href="https://jzxxx.github.io/"><img src="assets/img/organizer/zixiajia.jpg" class="img-fluid" alt="ShanghaiTech University"></a>
            </div>
            <div class="member-info text-center">
            <a href="https://jzxxx.github.io/"><h4>Zixia Jia</h4></a>
              <span>BigAI</span>
            </div>
          </div>



          <div class="col-lg-4 col-md-6 member" data-aos="fade-up" data-aos-delay="300">
            <div class="member-img">
            <a href="https://zilongzheng.github.io/"><img src="assets/img/organizer/zilong.jpg" class="img-fluid" alt="ShanghaiTech University"></a>
            </div>
            <div class="member-info text-center">
            <a href="https://zilongzheng.github.io/"><h4>Zilong Zheng</h4></a>
              <span>University of California, Los Angeles</span>
            </div>
          </div><!-- End Team Member -->




          <div class="col-lg-4 col-md-6 member" data-aos="fade-up" data-aos-delay="300">
            <div class="member-img">
            <a href="https://sites.google.com/view/yixin-homepage"><img src="assets/img/organizer/caoyixin.png" class="img-fluid" alt="Fudan University"></a>
            </div>
            <div class="member-info text-center">
            <a href="https://sites.google.com/view/yixin-homepage"><h4>Yixin Cao</h4></a>
              <span>Fudan University</span>
            </div>
          </div><!-- End Team Member -->





          <div class="col-lg-4 col-md-6 member" data-aos="fade-up" data-aos-delay="300">
            <div class="member-img">
            <a href="https://zhangmeishan.github.io/"><img src="assets/img/organizer/Meishan.png" class="img-fluid" alt="ShanghaiTech University"></a>
            </div>
            <div class="member-info text-center">
            <a href="https://zhangmeishan.github.io/"><h4>Meishan Zhang</h4></a>
              <span>Harbin Institute of Technology (Shenzhen)</span>
            </div>
          </div><!-- End Team Member -->




          <div class="col-lg-4 col-md-6 member" data-aos="fade-up" data-aos-delay="300">
            <div class="member-img">
            <a href="https://statnlp-research.github.io/"><img src="assets/img/organizer/lu-wei.jpg" class="img-fluid" alt="ShanghaiTech University"></a>
            </div>
            <div class="member-info text-center">
            <a href="https://statnlp-research.github.io/"><h4>Wei Lu</h4></a>
              <span>Singapore University of Technology and Design</span>
            </div>
          </div><!-- End Team Member -->





          <div class="col-lg-4 col-md-6 member" data-aos="fade-up" data-aos-delay="300">
            <div class="member-img">
            <a href="https://homepages.inf.ed.ac.uk/snaraya3/"><img src="https://edinburghnlp.inf.ed.ac.uk/wp-content/uploads/2024/07/sid.png" class="img-fluid" alt="ShanghaiTech University"></a>
            </div>
            <div class="member-info text-center">
            <a href="https://homepages.inf.ed.ac.uk/snaraya3/"><h4>N. Siddharth</h4></a>
              <span>University of Edinburgh</span>
            </div>
          </div><!-- End Team Member -->





          <div class="col-lg-4 col-md-6 member" data-aos="fade-up" data-aos-delay="300">
            <div class="member-img">
            <a href="https://www.mn.uio.no/ifi/english/people/aca/liljao/"><img src="assets/img/organizer/vlilja-ovrelid2.jpg" class="img-fluid" alt="ShanghaiTech University"></a>
            </div>
            <div class="member-info text-center">
            <a href="https://www.mn.uio.no/ifi/english/people/aca/liljao/"><h4>Lilja √òvrelid</h4></a>
              <span>University of Oslo</span>
            </div>
          </div><!-- End Team Member -->





          <div class="col-lg-4 col-md-6 member" data-aos="fade-up" data-aos-delay="300">
            <div class="member-img">
            <a href="https://www.cs.brandeis.edu/~xuen/"><img src="assets/img/organizer/nianwen-xue.jpg" class="img-fluid" alt="ShanghaiTech University"></a>
            </div>
            <div class="member-info text-center">
            <a href="https://www.cs.brandeis.edu/~xuen/"><h4>Nianwen Xue</h4></a>
              <span>Brandeis University</span>
            </div>
          </div><!-- End Team Member -->





          <div class="col-lg-4 col-md-6 member" data-aos="fade-up" data-aos-delay="300">
            <div class="member-img">
            <a href="https://frcchang.github.io/"><img src="assets/img/organizer/Yue-Zhang.jpg" class="img-fluid" alt="Westlake University"></a>
            </div>
            <div class="member-info text-center">
            <a href="https://frcchang.github.io/"><h4>Yue Zhang</h4></a>
              <span>Westlake University</span>
            </div>
          </div><!-- End Team Member -->





<!--          <div class="col-lg-4 col-md-6 member" data-aos="fade-up" data-aos-delay="600">-->
<!--            <div class="member-img">-->
<!--              <img src="assets/img/team/team-6.jpg" class="img-fluid" alt="">-->
<!--              <div class="social">-->
<!--                <a href="#"><i class="bi bi-twitter-x"></i></a>-->
<!--                <a href="#"><i class="bi bi-facebook"></i></a>-->
<!--                <a href="#"><i class="bi bi-instagram"></i></a>-->
<!--                <a href="#"><i class="bi bi-linkedin"></i></a>-->
<!--              </div>-->
<!--            </div>-->
<!--            <div class="member-info text-center">-->
<!--              <h4>Josepha Palas</h4>-->
<!--              <span>Operation</span>-->
<!--              <p>Sint sint eveniet explicabo amet consequatur nesciunt error enim rerum earum et omnis fugit eligendi cupiditate vel</p>-->
<!--            </div>-->
<!--          </div>&lt;!&ndash; End Team Member &ndash;&gt;-->

        </div>

      </div>

    </section><!-- /Team Section -->










    <!-- committee Section -->
    <section id="committee" class="committee section">

      <!-- Section Title -->
      <div class="container section-title" data-aos="fade-up">
        <h2>Program Committee</h2>
<!--        <p>Necessitatibus eius consequatur ex aliquid fuga eum quidem sint consectetur velit</p>-->
      </div><!-- End Section Title -->



<!--      <div class="container">-->
<!--          <p style="color: red;font-size: large;font-weight: bold;">- TBD -</p>-->
<!--      </div>-->


      <div class="container">

        <div class="row gy-2">

          <ul style="padding-left: 40px;line-height: 1.8;">

                <li> <a href="https://www3.nd.edu/~dchiang/">David Chiang</a>, University of Notre Dame </li>
<!--                <li> Yohei Oseki, University of Tokyo </li>-->
                <li> <a href="https://xuanjing-huang.github.io/">Huang Xuanjing</a>, Fudan University</li>
                <li> <a href="https://stanojevic.github.io/">Milos Stanojevic</a>, University College London </li>
                <li> <a href="https://jennhu.github.io/">Jennifer Hu</a>, Harvard University </li>
                <li> <a href="https://www.cylab.cmu.edu/directory/bios/li-lei.html">Lei Li</a>, Carnegie Mellon University </li>
                <li> <a href="https://jnivre.github.io/">Joakim Nivre</a>, Uppsala University </li>
                <li> <a href="https://mariannaapi.github.io/">Marianna Apidianaki</a>, University of Pennsylvania </li>
                <li> <a href="https://nlp.csai.tsinghua.edu.cn/~lzy/">Zhiyuan Liu</a>,  Tsinghua University</li>
                <li> <a href="https://profiles.auckland.ac.nz/liu-qian">Qian Liu</a>, University of Auckland</li>
                <li> <a href="https://pauillac.inria.fr/~seddah/">Djam√© Seddah</a>, University Paris-Sorbonne </li>
<!--                <li> <a href="http://hlt.suda.edu.cn/~zhli/en.html">Zhenghua Li</a>, Soochow University</li>-->
<!--                <li> Percy Liang, Stanford University </li>-->
<!--                <li> Dan Roth, University of Pennsylvania </li>-->
<!--                <li> Luke Zettlemoyer, University of Washington </li>-->

                <li> <a href="https://sustcsonglin.github.io/">Songlin Yang</a>, Massachusetts Institute of Technology </li>
                <li> <a href="https://www.emorynlp.org/bachelors/jayeol-chun">Jayeol Chun</a>, Brandeis University</li>
                <li> <a href="https://liziliao.github.io/">Lizi Liao</a>, Singapore Management University</li>
                <li> <a href="https://people.cs.georgetown.edu/nschneid/">Natha Schneider</a>, Georgetown University </li>
                <li> <a href="https://zcli-charlie.github.io/">Zuchao Li</a>, Wuhan University </li>
                <li> <a href="https://attapol.github.io/">Attapol Rutherford</a>, Chulalongkorn University </li>
                <li> <a href="https://xinyadu.github.io/">Xinya Du</a>, University of Texas at Dallas </li>
                <li> <a href="https://cs.uwaterloo.ca/~fhs/">Freda Shi</a>, University of Waterloo</li>

                <li> <a href="https://jflanigan.github.io/">Jeff Flanigan</a>, University of California, Santa Cruz</li>
                <li> <a href="https://people.ucas.ac.cn/~hongyu">Hongyu Lin</a>, Chinese Academy of Sciences </li>
                <li> <a href="https://jinlanfu.github.io/">Jinlan Fu</a>, National University of Singapore</li>
                <li> <a href="https://liangmingpan.bio/">Liangming Pan</a>, University of Arizona </li>


                <li> <a href="https://namednil.github.io/">Matthias Lindemann</a>, University of Edinburgh </li>
                <li> <a href="https://bcmi.sjtu.edu.cn/home/zhangzs/">Zhuosheng Zhang</a>, Shanghai Jiao Tong University</li>
                <li> <a href="https://mopper97.github.io/">Mattia Opper</a>, University of Edinburgh </li>
                <li> <a href="#">Yanpeng Zhao</a>, Beijing Institute for General Artificial Intelligence </li>
                <li> <a href="https://shirawein.github.io/">Shira Wein</a>, Amherst College </li>

                <li> <a href="https://sph.nus.edu.sg/faculty-directory/he-kai/">He Kai</a>, National University of Singapore </li>
                <li> <a href="https://wenyueh.github.io/">Wenyue Hua</a>, University of California, Santa Barbara </li>


                <li> <a href="https://cs.stanford.edu/~anjiang/">Anjiang Wei</a>, Stanford University</li>
                <li> <a href="https://yoshiryo0617.github.io/github-pages/">Ryo Yoshida</a>, University of Tokyo </li>
                <li> <a href="https://lilei-nlp.github.io/">Lei Li</a>, University of Hong Kong</li>
                <li> <a href="https://www.colorado.edu/linguistics/julia-bonn">Julia Bonn</a>, University of Colorado at Boulder</li>

                <li> <a href="#">Chao Lou</a>, ShanghaiTech University</li>
                <li> <a href="#">Haoyi Wu</a>, ShanghaiTech University</li>
                <li> <a href="https://yzhang.site/">Yu Zhang</a>, Soochow University </li>
                <li> <a href="https://sqwu.top/">Shengqiong Wu</a>, National University of Singapore </li>
                <li> <a href="https://jrc1995.github.io/">Jishnu Ray Chowdhury</a>, University of Illinois Chicago </li>


<!--              =========================-->

<!--                <li> Ryan Cotterell, ETH Z√ºrich </li>-->
<!--                <li> Scott Wen-tau Yih, Meta AI </li>-->

<!--                <li> Min-Yen Kan, National University of Singapore </li>-->
<!--                <li> Ryan McDonald, Microsoft Research </li>-->
<!--                <li> Alexander Clark, Gothenburg University </li>-->
<!--                <li> Heng Ji, University of Illinois Urbana-Champaign </li>-->
<!--                <li> Xuanjing Huang, Fudan University </li>-->
<!--                <li> Erik Cambria, Nanyang Technological University </li>-->
<!--                <li> Luheng He, Google </li>-->
<!--                <li> Freda Shi, University of Waterloo </li>-->
<!--                <li> Yikang Shen, MIT-IBM Watson Lab </li>-->
<!--                <li> Jan Hajiƒç, Charles University </li>-->


          </ul>


      </div>

    </section><!-- /committee Section -->
















    <!-- Contact Section -->
    <section id="contact" class="contact section">

      <!-- Section Title -->
      <div class="container section-title" data-aos="fade-up">
        <h2>Contact</h2>
<!--        <p>Necessitatibus eius consequatur ex aliquid fuga eum quidem sint consectetur velit</p>-->
      </div><!-- End Section Title -->

      <div class="container" data-aos="fade-up" data-aos-delay="100">

        <div>
          <h5>Join and post at our <a href="https://groups.google.com/g/xllm2025">Google Group</a>!</h5>
          <h5>Email the organziers at <a href="mailto:xllm2025@googlegroups.com ">xllm2025@googlegroups.com</a>.</h5>

        </div>


      </div>

    </section><!-- /Contact Section -->

  </main>


  <footer id="footer" class="footer position-relative light-background" style="
    padding-bottom: 0;
">


    <div class="container copyright text-center mt-4" style="
    background-color: transparent;
">
      <p>¬© <span>Copyright</span> <strong class="sitename">Append</strong> <span>All Rights Reserved</span></p>
      <div class="credits">
        <!-- All the links in the footer should remain intact. -->
        <!-- You can delete the links only if you've purchased the pro version. -->
        <!-- Licensing information: https://bootstrapmade.com/license/ -->
        <!-- Purchase the pro version with working PHP/AJAX contact form: [buy-url] -->
        Designed by <a href="https://bootstrapmade.com/">BootstrapMade</a>
      </div>
    </div>

  </footer>

  <!-- Scroll Top -->
  <a href="#" id="scroll-top" class="scroll-top d-flex align-items-center justify-content-center"><i class="bi bi-arrow-up-short"></i></a>

  <!-- Preloader -->
  <div id="preloader"></div>

  <!-- Vendor JS Files -->
  <script src="assets/vendor/bootstrap/js/bootstrap.bundle.min.js"></script>
  <script src="assets/vendor/php-email-form/validate.js"></script>
  <script src="assets/vendor/aos/aos.js"></script>
  <script src="assets/vendor/glightbox/js/glightbox.min.js"></script>
  <script src="assets/vendor/purecounter/purecounter_vanilla.js"></script>
  <script src="assets/vendor/imagesloaded/imagesloaded.pkgd.min.js"></script>
  <script src="assets/vendor/isotope-layout/isotope.pkgd.min.js"></script>
  <script src="assets/vendor/swiper/swiper-bundle.min.js"></script>

  <!-- Main JS File -->
  <script src="assets/js/main.js"></script>

</body>

</html>